{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "90f7199d-c442-4732-ab89-83bda42682a7",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "90f7199d-c442-4732-ab89-83bda42682a7",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "de21aae042b148f4ce345abc2630f326",
          "grade": false,
          "grade_id": "cell-b2bf973e50b54a30",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "# Machine Translation with Transformers\n",
        "\n",
        "In this project, I will explore the Transformer-based neural architecture by tackling a machine translation task. Machine translation involves translating text from a source language to a target language. Traditionally, machine translation was performed using recurrent neural network (RNN)-based architectures. However, the emergence of Transformers has marked a revolutionary shift in the fields of text analysis and especially machine translation.\n",
        "\n",
        "Transformers offer several advantages over earlier RNN-based models for the machine translation task:\n",
        "\n",
        "* One major benefit is their ability to capture context from a long sequence using self-attention layers, which allows the model to retain relevant information from words further back in the text.\n",
        "  \n",
        "* Additionally, Transformers improve the natural flow and grammatical accuracy of translated sentences. Unlike RNN models, which tend to follow the word order of the source language, Transformers utilize cross-attention layers between the source and target languages. This allows them to arrange translated words in an order that sounds more natural in the target language, even if it differs significantly from the source structure.\n",
        "  \n",
        "* Finally, Transformers enable parallelization, which makes it feasible to train them on multiple GPUs, speeding up the training process.\n",
        "\n",
        "### **Data**\n",
        "\n",
        "The dataset used for this project consists of a set of French sentences and their equivalent English translations.\n",
        "\n",
        "### **Useful links**\n",
        "\n",
        "* https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
        "* https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b6f8445f",
      "metadata": {
        "editable": true,
        "id": "b6f8445f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "skip_training = False   # You can set it to True if you want to run inference on your trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4929157-7d8f-4e84-85f6-c56ea7093ae1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b4929157-7d8f-4e84-85f6-c56ea7093ae1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "188b80bd0b4c8442090aaa7246bee938",
          "grade": false,
          "grade_id": "cell-172f7e1657a03eb1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "Add path to the folder containing csv files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "959359d2-e60b-4dec-a5eb-d7dabe3f1a5f",
      "metadata": {
        "editable": true,
        "id": "959359d2-e60b-4dec-a5eb-d7dabe3f1a5f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "path = \"/content/dataset_ex5\" # you can change the path if you want to store the dataset somewhere else."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbdb6f08",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cbdb6f08",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8527fd780788625a34b40348b30de440",
          "grade": false,
          "grade_id": "cell-39478e54ddb16815",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "Import all necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0b6feccd",
      "metadata": {
        "editable": true,
        "id": "0b6feccd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set random seeds for all libraries\n",
        "import random\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "torch.cuda.manual_seed(1)\n",
        "torch.cuda.manual_seed_all(1)\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607dc4e5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "607dc4e5",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "535faf5a7df324791294b2fd542d2d89",
          "grade": false,
          "grade_id": "cell-815c797e06bdf55a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "Select the device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1a9f32a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "1a9f32a0",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "310824e7fb50a67093ebb7f92521f386",
          "grade": false,
          "grade_id": "cell-3ac688ddcdf1f718",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "abc3a878-aded-444b-adf4-3d0b5f81980d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "219ed6c0-92b9-4ca5-8b9f-71995799314f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "219ed6c0-92b9-4ca5-8b9f-71995799314f",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "851f4281950105edf2038c35a19db963",
          "grade": false,
          "grade_id": "cell-91357d14fc99d39d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "## 1: Data Preparation\n",
        "\n",
        "In this task, I will preprocess the dataset to convert it into a format suitable for input to a Transformer neural model. Each subtask focuses on a specific step in the preprocessing pipeline.\n",
        "\n",
        "### Summary of Tasks for This Stage\n",
        "\n",
        "**Task 1.1: Tokenizaion** \n",
        "\n",
        "**Task 1.2: Building Vocabulary** \n",
        "\n",
        "**Task 1.3: Sentence Embedding** \n",
        "\n",
        "**Task 1.4: Positional Encoding** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9febf38-0a1a-4ff3-94a7-eb232c21eef1",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b9febf38-0a1a-4ff3-94a7-eb232c21eef1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7f4723736e3e4512d6d08504b7a0dbd6",
          "grade": false,
          "grade_id": "cell-291860bd3393c1d3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "### Task 1.1: Tokenizaion\n",
        "\n",
        "In this task, we use a basic tokenization method for simplicity and to avoid potential library mismatch issues that could arise across different students' systems and environments. While more advanced tokenization methods are available through specialized libraries, this basic approach ensures consistency and focuses on the core concept of tokenization. Our method uses Python's built-in tools and includes the following steps:\n",
        "\n",
        "1. Lowercasing: Convert all characters in the sentence to lowercase.\n",
        "2. Filtering Characters: Define a set of characters to be removed from the sentences, replacing them with an empty string.\n",
        "3. Splitting: Split the sentence into tokens based on spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "04ecf7ac-b2ce-4e9e-9560-8bc53c616282",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": false,
        "id": "04ecf7ac-b2ce-4e9e-9560-8bc53c616282",
        "outputId": "8c1d5d6d-c71b-4df5-841c-caa4b5a46c2b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 137860 English sentences in data\n",
            "There are 137860 French sentences in data\n",
            "Here are some examples:\n",
            "----------\n",
            "new jersey is sometimes quiet during autumn \n",
            "new jersey est parfois calme pendant l' automne \n",
            "----------\n",
            "they like strawberries \n",
            "ils aiment les fraises \n",
            "----------\n",
            "she plans to visit the united states next may .\n",
            "elle envisage de se rendre aux états-unis en mai prochain .\n",
            "____________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Load your data\n",
        "en_df = pd.read_csv(os.path.join(path , 'small_vocab_en.csv'), header=None, usecols=[0])\n",
        "fr_df = pd.read_csv(os.path.join(path, 'small_vocab_fr.csv'), header=None, usecols=[0])\n",
        "\n",
        "english_sentences = en_df[0].values\n",
        "french_sentences = fr_df[0].values\n",
        "\n",
        "print(f'There are {len(english_sentences)} English sentences in data')\n",
        "print(f'There are {len(french_sentences)} French sentences in data')\n",
        "print('Here are some examples:')\n",
        "e = [ 0, 1000, 3000]\n",
        "for i in e:\n",
        "    print(10*\"-\")\n",
        "    print(english_sentences[i])\n",
        "    print(french_sentences[i])\n",
        "print(100*\"_\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "05a18098-1a7f-4758-84f4-4a7f6bfa40d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": true,
        "id": "05a18098-1a7f-4758-84f4-4a7f6bfa40d3",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e136e2d6e0d0fe41dcc0ed1b4265e4b3",
          "grade": false,
          "grade_id": "cell-d953178b4a066fcc",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "19db4bd1-126f-4a42-ae7a-a1b455cdb745",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------\n",
            "['new', 'jersey', 'is', 'sometimes', 'quiet', 'during', 'autumn']\n",
            "['new', 'jersey', 'est', 'parfois', 'calme', 'pendant', \"l'\", 'automne']\n",
            "----------\n",
            "['they', 'like', 'strawberries']\n",
            "['ils', 'aiment', 'les', 'fraises']\n",
            "----------\n",
            "['she', 'plans', 'to', 'visit', 'the', 'united', 'states', 'next', 'may']\n",
            "['elle', 'envisage', 'de', 'se', 'rendre', 'aux', 'étatsunis', 'en', 'mai', 'prochain']\n"
          ]
        }
      ],
      "source": [
        "# Tokenize function\n",
        "def tokenize(sentences):\n",
        "    \"\"\"\n",
        "    Tokenizes a list of sentences by:\n",
        "    1. Converting all text to lowercase.\n",
        "    2. Removing special characters listed in \"filters\".\n",
        "    Hint: you can use \"str.maketrans\" to creates a translation table to remove unwanted characters defined in \"filters\".\n",
        "    3. Splitting each sentence into a list of words.\n",
        "    \"\"\"\n",
        "    filters = '.?!#$%&()*+,-/:;<=>@«»\"\"[\\\\]^_`{|}~\\t\\n'\n",
        "    filtered = str.maketrans('', '', filters)\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    tokenized_list = []\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.lower()\n",
        "        sentence = sentence.translate(filtered)\n",
        "        tokenized_list.append(sentence.split())\n",
        "\n",
        "    return tokenized_list\n",
        "\n",
        "# Tokenize English and French sentences\n",
        "tokenized_en = tokenize(english_sentences)\n",
        "tokenized_fr = tokenize(french_sentences)\n",
        "for i in e:\n",
        "    print(10*\"-\")\n",
        "    print(tokenized_en[i])\n",
        "    print(tokenized_fr[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aa45a918-bf00-4e55-b019-931c192d0d31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "aa45a918-bf00-4e55-b019-931c192d0d31",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "669ef31e0c8851864a0dd34bbc381a22",
          "grade": true,
          "grade_id": "cell-ddea51129d5d8a84",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "2ffda50e-1d6e-4283-dd33-196423408b03",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed: The tokenize function is working as expected.\n"
          ]
        }
      ],
      "source": [
        "# Visible tests here\n",
        "\n",
        "# Test the tokenize function with example sentences\n",
        "test_sentences = [\"Hello, world!\", \"Python is fun.\", \"Let's tokenize this: right?\"]\n",
        "\n",
        "# Expected output: lowercase, special characters removed, tokenized words\n",
        "expected_output = [\n",
        "    [\"hello\", \"world\"],\n",
        "    [\"python\", \"is\", \"fun\"],\n",
        "    [\"let's\", \"tokenize\", \"this\", \"right\"]\n",
        "]\n",
        "\n",
        "# Run the student's tokenize function\n",
        "tokenized_output = tokenize(test_sentences)\n",
        "\n",
        "# Check if the output matches the expected output\n",
        "assert tokenized_output == expected_output, (\n",
        "    f\"Test failed!\\nExpected: {expected_output}\\nGot: {tokenized_output}\")\n",
        "print(\"Test passed: The tokenize function is working as expected.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc71a52-0148-4bce-af72-799047b0f653",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bfc71a52-0148-4bce-af72-799047b0f653",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0907496be0bbf0e8a9587a38d054ac63",
          "grade": false,
          "grade_id": "cell-5c42169eb0d9ba7c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "### Task 1.2: Building Vocabulary\n",
        "\n",
        "In this step, we will convert tokenized sentences into lists of integers. This is achieved by defining a dictionary of unique words for each language and assigning a unique integer to each word.\n",
        "\n",
        "In addition to the set of unique words in the dataset, the vocabulary must include three special tokens:\n",
        "\n",
        "1.  PAD: Padding Token (0)\n",
        "2.  SOS: Start of Sentence (1)\n",
        "3.  EOS: End of Sentence (2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ee1d488c-b866-46da-91c9-857bc7540d7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": true,
        "id": "ee1d488c-b866-46da-91c9-857bc7540d7b",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54b4b871a691fb80fb59f818abe16af6",
          "grade": false,
          "grade_id": "cell-acd8f7a88e74d5a4",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "622006a6-cbc4-46ef-8def-ac52f1a9936e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are some examples from our English dictionary: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "word: <PAD>, index: 0\n",
            "word: <SOS>, index: 1\n",
            "word: <EOS>, index: 2\n",
            "word: new, index: 3\n",
            "word: jersey, index: 4\n",
            "word: is, index: 5\n",
            "word: sometimes, index: 6\n",
            "word: quiet, index: 7\n",
            "word: during, index: 8\n",
            "word: autumn, index: 9\n",
            "__________\n",
            "index: 0, word: <PAD>\n",
            "index: 1, word: <SOS>\n",
            "index: 2, word: <EOS>\n",
            "index: 3, word: new\n",
            "index: 4, word: jersey\n",
            "index: 5, word: is\n",
            "index: 6, word: sometimes\n",
            "index: 7, word: quiet\n",
            "index: 8, word: during\n",
            "index: 9, word: autumn\n"
          ]
        }
      ],
      "source": [
        "# Create vocabulary with special tokens\n",
        "def build_vocab(tokenized_sentences):\n",
        "    special_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "    # build vocab by applying \"Counter\" for sentence in tokenized_sentences and for token in sentence\n",
        "    # add special tokens\n",
        "    # word2idx = ? (a dictionary for mapping word to index)\n",
        "    # idx2word = ? (a dictionary for index to word)\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    word_counter = Counter()\n",
        "    for sentence in tokenized_sentences:\n",
        "        for token in sentence:\n",
        "            word_counter[token] += 1\n",
        "\n",
        "    word2idx = {word: idx for idx, word in enumerate(special_tokens + list(word_counter.keys()))}\n",
        "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "\n",
        "    return word2idx, idx2word\n",
        "\n",
        "en_word2idx, en_idx2word = build_vocab(tokenized_en)\n",
        "fr_word2idx, fr_idx2word = build_vocab(tokenized_fr)\n",
        "\n",
        "print(\"Here are some examples from our English dictionary: \")\n",
        "print(100 * \"-\")\n",
        "\n",
        "# Display first 10 words and their indices from en_word2idx\n",
        "for i, (key, value) in enumerate(en_word2idx.items()):\n",
        "    print(f'word: {key}, index: {value}')\n",
        "    if i == 9:  # After 10 iterations, break\n",
        "        break\n",
        "\n",
        "print(10 * \"_\")\n",
        "\n",
        "# Display first 10 indices and their words from en_idx2word\n",
        "for i, (key, value) in enumerate(en_idx2word.items()):\n",
        "    print(f'index: {key}, word: {value}')\n",
        "    if i == 9:  # After 10 iterations, break\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f547dd82-5bb6-47fb-b0dc-b0800fb904b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "f547dd82-5bb6-47fb-b0dc-b0800fb904b3",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb9622630aba9ccc7f1c35973ebe1fb1",
          "grade": true,
          "grade_id": "cell-ba37faad4f92cb66",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "e95e7f64-bfb5-49df-e3a8-3e5b8ec64128",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary test passed!\n"
          ]
        }
      ],
      "source": [
        "# Visible tests here\n",
        "\n",
        "# Test: Check if the vocabulary is built correctly\n",
        "\n",
        "# Tokenized test data\n",
        "sample_tokenized_sentences = [[\"hello\", \"world\"], [\"hello\", \"my\", \"friend\"]]\n",
        "\n",
        "# Expected results\n",
        "expected_special_tokens = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "expected_vocab = expected_special_tokens + [\"friend\", \"hello\", \"my\", \"world\"]\n",
        "\n",
        "# Build vocabulary\n",
        "word2idx, idx2word = build_vocab(sample_tokenized_sentences)\n",
        "\n",
        "# Test special tokens are present and in correct order\n",
        "assert all(token in word2idx for token in expected_special_tokens), \"Special tokens missing from vocabulary\"\n",
        "assert word2idx[\"<PAD>\"] == 0, \"<PAD> token index is incorrect\"\n",
        "assert word2idx[\"<SOS>\"] == 1, \"<SOS> token index is incorrect\"\n",
        "assert word2idx[\"<EOS>\"] == 2, \"<EOS> token index is incorrect\"\n",
        "\n",
        "# Test all unique words are present and sorted correctly\n",
        "assert sorted(word2idx.keys()) == sorted(expected_vocab), \"Vocabulary does not match expected words\"\n",
        "assert len(word2idx) == len(idx2word), \"Mismatch between word2idx and idx2word lengths\"\n",
        "assert all(idx2word[word2idx[word]] == word for word in word2idx), \"word2idx and idx2word mappings are incorrect\"\n",
        "\n",
        "print(\"Vocabulary test passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4604ca38-063e-46cb-a40e-57192653a316",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4604ca38-063e-46cb-a40e-57192653a316",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "dc164a3386abefc31af298f532ab98d0",
          "grade": false,
          "grade_id": "cell-2b2c9232a9907c80",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "### Dataset Class\n",
        "\n",
        "In this step, we will use a custom dataset class specifically designed for our translation task. This class incorporates essential preprocessing steps, such as padding, truncation, and the addition of special tokens.\n",
        "\n",
        "As discussed earlier, sentences in our dataset have varying lengths. To ensure all sentences are of the same length (a requirement for the Transformer model), we will define a fixed length for input sequences. The preprocessing steps performed by the dataset class include:\n",
        "\n",
        "* Special Tokens: The 'SOS' token is added at the beginning of each sentence, and the 'EOS' token is added at the end.\n",
        "* Truncation: Sentences that exceed the defined maximum length will be truncated to fit the specified length.\n",
        "* Padding: The 'PAD' token is appended to sentences shorter than the maximum length until they reach the required length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "742ff0d6-758b-43c6-a870-aab4a73746dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": true,
        "id": "742ff0d6-758b-43c6-a870-aab4a73746dd",
        "outputId": "24b2a666-b6cd-48e0-d707-aef8e65851b5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source batch: tensor([[  1,  39,  65,   5,   6, 104,  15,  64,   2,   0]], device='cuda:0')\n",
            "torch.Size([1, 10])\n",
            "__________\n",
            "Target batch: tensor([[ 1, 58,  5,  6, 87,  8, 57,  2,  0,  0]], device='cuda:0')\n",
            "torch.Size([1, 10])\n",
            "__________\n"
          ]
        }
      ],
      "source": [
        "# Dataset class with padding applied in __getitem__\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab, seq_len=30):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.tgt_sentences = tgt_sentences\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def pad_sequence(self, tokens, vocab, is_target=False):\n",
        "        \"\"\"\n",
        "        Pads a sequence of tokens to the fixed length `seq_len`.\n",
        "        Adds <SOS> at the start, <EOS> at the end, and pads with <PAD>.\n",
        "        Trims if the sequence is longer than `seq_len`.\n",
        "        \"\"\"\n",
        "        tokens = [vocab[\"<SOS>\"]] + [vocab.get(token, vocab[\"<PAD>\"]) for token in tokens]\n",
        "        tokens.append(vocab[\"<EOS>\"])\n",
        "        tokens = tokens[:self.seq_len]\n",
        "        tokens += [vocab[\"<PAD>\"]] * (self.seq_len - len(tokens))\n",
        "        return tokens\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        src_tokens = self.src_sentences[idx]\n",
        "        tgt_tokens = self.tgt_sentences[idx]\n",
        "\n",
        "        # Apply padding to both the source and target sentences\n",
        "        src_padded = self.pad_sequence(src_tokens, self.src_vocab, is_target=False)\n",
        "        tgt_padded = self.pad_sequence(tgt_tokens, self.tgt_vocab, is_target=True)\n",
        "\n",
        "        # Convert to tensors and move to device (GPU or CPU)\n",
        "        src_item = torch.tensor(src_padded).to(device)\n",
        "        tgt_item = torch.tensor(tgt_padded).to(device)\n",
        "\n",
        "        return src_item, tgt_item\n",
        "\n",
        "# Instantiate and test the dataset, let the French be as source language and English as target language.\n",
        "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Test the DataLoader\n",
        "for src_batch, tgt_batch in dataloader:\n",
        "    print(\"Source batch:\", src_batch)\n",
        "    print(src_batch.size())\n",
        "    print(10*\"_\")\n",
        "    print(\"Target batch:\", tgt_batch)\n",
        "    print(tgt_batch.size())\n",
        "    print(10*\"_\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9cbf6fe-050c-4357-ae8f-112a4021b231",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c9cbf6fe-050c-4357-ae8f-112a4021b231",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a920ba916dac6fa8032a24c0603867eb",
          "grade": false,
          "grade_id": "cell-5ddb30e4fc5234fa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "### Task 1.3: Sentence Embedding\n",
        "\n",
        "Words, by themselves, are discrete symbols that neural networks cannot process directly. To make them understandable to the model, we use **embedding layers**. These layers transform words or tokens into dense, fixed-size vectors, where each word is represented by a unique vector. The embedding layer maps words into a continuous vector space, enabling semantically similar words to be closer to each other in this space. This approach is far more compact and efficient than sparse, high-dimensional representations like one-hot encoding.\n",
        "\n",
        "Embedding layers are particularly useful in natural language processing tasks such as **machine translation**, where words in different languages must be represented in a way that enables the model to learn their relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9fe7f794-94bc-4332-a186-7c0d11fc218f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": true,
        "id": "9fe7f794-94bc-4332-a186-7c0d11fc218f",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2e641ffdf106f543f00d6a776e3963eb",
          "grade": false,
          "grade_id": "cell-fab72a3e23c8b68e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "b6471ffa-69f1-4671-bf5b-fccf80016ee7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__________\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10, 128])\n",
            "__________\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10, 128])\n"
          ]
        }
      ],
      "source": [
        "embedding_size = 128\n",
        "vsize_src = len(fr_word2idx)\n",
        "vsize_tgt = len(en_word2idx)\n",
        "\n",
        "# data: let the French be as source language and English as target language.\n",
        "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Use 'next' to get a batch from the DataLoader iterator\n",
        "src_batch, tgt_batch = next(iter(dataloader))\n",
        "\n",
        "# embedding_fr = ? (define an embedding layer for French words in your French Vocabulary)\n",
        "embedding_fr = nn.Embedding(vsize_src, embedding_size)\n",
        "embedding_fr.to(device)\n",
        "# output_embedding_fr = ? (pass src_batch through embedding_fr)\n",
        "output_embedding_fr = embedding_fr(src_batch)\n",
        "\n",
        "# embedding_en = ? (define an embedding layer for English words in your English Vocabulary)\n",
        "embedding_en = nn.Embedding(vsize_tgt, embedding_size)\n",
        "embedding_en.to(device)\n",
        "# output_embedding_en = ?\n",
        "output_embedding_en = embedding_en(tgt_batch)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "print(10*\"_\")\n",
        "print(src_batch.size())\n",
        "print(output_embedding_fr.size())\n",
        "print(10*\"_\")\n",
        "print(tgt_batch.size())\n",
        "print(output_embedding_en.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "30669a20-b2f9-4e86-96ac-15af4cdb01b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "30669a20-b2f9-4e86-96ac-15af4cdb01b9",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d2b92c388bc76a10fd0d9eb5193c0008",
          "grade": true,
          "grade_id": "cell-3e23c383eb021716",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "c8bb5be4-920b-43f7-9531-0c523db5c9e2",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings are correctly implemented!\n"
          ]
        }
      ],
      "source": [
        "# Visible tests here\n",
        "\n",
        "# Check if the embeddings have the correct output shapes\n",
        "assert output_embedding_fr.shape == (src_batch.size(0), src_batch.size(1), embedding_size), \"Embedding for French is incorrect!\"\n",
        "assert output_embedding_en.shape == (tgt_batch.size(0), tgt_batch.size(1), embedding_size), \"Embedding for English is incorrect!\"\n",
        "\n",
        "print(\"Embeddings are correctly implemented!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce8ae0f-ece1-4596-8037-89631b8d2075",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1ce8ae0f-ece1-4596-8037-89631b8d2075",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "478bcf1a7168a93463c0482b18b80bbf",
          "grade": false,
          "grade_id": "cell-8372a80b53e83a10",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "### Task 1.4: Positional encoding\n",
        "\n",
        "In sequence models like the Transformer, the model needs a way to understand the relative positions of words in a sequence. Since the Transformer model does not inherently process sequential data in a time-dependent manner (unlike RNNs or LSTMs), we need to explicitly provide information about the position of each word in the input sequence.\n",
        "\n",
        "The Positional Encoding layer is used to add this positional information to the word embeddings. It generates a vector for each position in the sequence and combines it with the word embedding to provide both the content and position information. The positional encoding is computed using sine and cosine functions of different wavelengths, which allows the model to easily learn relative positions.\n",
        "\n",
        "In this step, I will implement the Positional Encoding layer:\n",
        "\n",
        "1. Compute the positional encodings using sine and cosine functions.\n",
        "2. Register the positional encodings as a buffer so they are not considered trainable parameters.\n",
        "3. Add the positional encoding to the word embeddings during the forward pass.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dfbfdac1-3bd3-4a57-b034-4aeb97cf1b9d",
      "metadata": {
        "deletable": false,
        "editable": true,
        "id": "dfbfdac1-3bd3-4a57-b034-4aeb97cf1b9d",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "66ff2d4d083b95d6edb7f6e17233b63e",
          "grade": false,
          "grade_id": "cell-de1d08bfdff6d81e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_size, max_len=512):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        # Initialize a tensor to store positional encodings for each position up to max_len\n",
        "        pos_encoding = torch.zeros(max_len, embed_size)\n",
        "        # Create a tensor for positions, where each position corresponds to a word's position in the sequence\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # 1. Create a tensor `div_term` to scale the positional encoding values.\n",
        "\n",
        "        # Hint:\n",
        "        # This is based on the formula for positional encoding where each dimension has a different frequency.\n",
        "        # We generate a range of values from 0 to embed_size, stepping by 2 (for even indices), and multiply it by a scaling factor.\n",
        "        # The scaling factor (-math.log(10000.0) / embed_size) ensures the frequencies decay logarithmically.\n",
        "\n",
        "        # 2. Apply the sine function to the even indices of the positional encoding matrix.\n",
        "        # 3. Apply the cosine function to the odd indices of the positional encoding matrix.\n",
        "\n",
        "        # Hint:\n",
        "        # The `position` tensor holds the position values for each token, and `div_term` scales those values.\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        div_term = torch.exp(torch.arange(0, embed_size, 2).float() * (-math.log(10000.0) / embed_size))\n",
        "        pos_encoding[:, 0::2] = torch.sin(position * div_term)\n",
        "        pos_encoding[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Register as buffer so it is not considered as a parameter during training\n",
        "        self.register_buffer('pos_encoding', pos_encoding.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add positional encoding to embeddings\n",
        "        x = x * math.sqrt(self.embed_size)\n",
        "        x = x + self.pos_encoding[:, :x.size(1), :].to(x.device)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f3a3335e-1dff-4fe8-aebd-8367d2359da5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": false,
        "id": "f3a3335e-1dff-4fe8-aebd-8367d2359da5",
        "outputId": "3ecb4c03-aa1c-46aa-f72e-f1ea05093d5f",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__________\n",
            "torch.Size([1, 10, 128])\n",
            "torch.Size([1, 10, 128])\n"
          ]
        }
      ],
      "source": [
        "#%% Applying positional encoding\n",
        "positional_encoding = PositionalEncoding(embedding_size, 512)\n",
        "output_pe_fr = positional_encoding (output_embedding_fr)\n",
        "output_pe_en = positional_encoding (output_embedding_en)\n",
        "print(10*\"_\")\n",
        "print(output_pe_fr.size())\n",
        "print(output_pe_en.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6fa00a4a-cbc5-4ef4-873f-b4d0dafa33ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "6fa00a4a-cbc5-4ef4-873f-b4d0dafa33ea",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "40f67672dff380019505babbe8448301",
          "grade": true,
          "grade_id": "cell-24f5a81611dd6e96",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "b0751f82-2ae5-4617-f4b4-3af00075f3c9",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positional Encoding has been implemented correctly!\n"
          ]
        }
      ],
      "source": [
        "# Visible tests here\n",
        "\n",
        "# Test if positional encoding has been implemented correctly\n",
        "\n",
        "# Initialize the positional encoding with a fixed embed size and max_len\n",
        "test_pos_enc = PositionalEncoding(embed_size=128, max_len=512)\n",
        "\n",
        "# Let's assume the input sequence is a batch of embeddings (value doesn't matter for this test)\n",
        "src_batch = torch.zeros(1, 10, 128)  # batch_size=1, seq_len=10, embed_size=128\n",
        "tgt_batch = torch.zeros(1, 10, 128)\n",
        "\n",
        "# Pass through the positional encoding layer\n",
        "encoded_src_batch = test_pos_enc(src_batch)\n",
        "encoded_tgt_batch = test_pos_enc(tgt_batch)\n",
        "\n",
        "# Check the output dimensions\n",
        "assert encoded_src_batch.size() == src_batch.size(), f\"Expected {src_batch.size()}, but got {encoded_src_batch.size()}\"\n",
        "assert encoded_tgt_batch.size() == tgt_batch.size(), f\"Expected {tgt_batch.size()}, but got {encoded_tgt_batch.size()}\"\n",
        "\n",
        "# Check if positional encoding is working correctly\n",
        "\n",
        "# Ensure that adding positional encoding to embeddings changes the values\n",
        "# The output at the first position should be different than at other positions (if positional encoding is applied correctly)\n",
        "assert not torch.allclose(encoded_src_batch[:, 0, :], encoded_src_batch[:, 1, :], atol=1e-5), \\\n",
        "    \"Positional encoding should differentiate between different positions in the sequence.\"\n",
        "\n",
        "print(\"Positional Encoding has been implemented correctly!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6baf7c61-c078-45c3-977e-fbefe51e3beb",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6baf7c61-c078-45c3-977e-fbefe51e3beb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "29456a0467e8a115f33b88974dd4d293",
          "grade": false,
          "grade_id": "cell-093e16e5c4566696",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 2: Model Architecture\n",
        "\n",
        "### Summary of Tasks for This Stage\n",
        "\n",
        "**Task 2.1: Designing a basic transformer block** \n",
        "\n",
        "**Task 2.2: Adding Encoder and Decoder blocks** "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1ff3a1-5f60-4baa-9eb9-17d899db9df5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "de1ff3a1-5f60-4baa-9eb9-17d899db9df5",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b95686179c6ec14218111c952981a8a7",
          "grade": false,
          "grade_id": "cell-791a329ab0d9161b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "### Task 2.1: Designing a basic transformer block\n",
        "\n",
        "In this task, I will implement a simple Transformer model. This model will take source and target sequences as input, apply embeddings and positional encodings, pass the result through a Transformer block, and finally project the output to the target vocabulary space. Before passing the input through the Transformer block, we need to compute two types of masks:\n",
        "\n",
        "**Padding Mask:** This mask is applied to the source sequence and to the target sequence to prevent the model from attending to padding tokens, which should be ignored during training. The padding mask is implemented in the create_pad_mask method.\n",
        "\n",
        "**Target Mask (tgt_mask):** This mask is used to prevent the model from using future target steps to predict the current output. If the model could access future information, it would already know the solution, making training redundant. The tgt_mask helps ensure causal attention by masking out future tokens in the target sequence.\n",
        "\n",
        "These two masks are essential for enabling effective training and maintaining the correct flow of information through the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b5f4ccdb-b179-4d23-952d-bdc91600d5b6",
      "metadata": {
        "deletable": false,
        "editable": true,
        "id": "b5f4ccdb-b179-4d23-952d-bdc91600d5b6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6dbbb12193d9b79028864bbc728a7d9e",
          "grade": false,
          "grade_id": "cell-2c2066cf6ea79138",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class MySimpleTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size_src, vocab_size_tgt, embed_size, num_heads, hidden_dim, num_encoder_layers, num_decoder_layers, max_len=512):\n",
        "        super(MySimpleTransformer, self).__init__()\n",
        "        # Initialize layers as below:\n",
        "        # Embedding layer for source language tokens\n",
        "        # embedding layer for target langauge tokens\n",
        "        # Positional encoding\n",
        "        # Transformer block (Hint: use nn.Transformer)\n",
        "        # Final linear layer to project transformer output to vocab size (Hint: use nn.Linear)\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        self.embedding_source = nn.Embedding(vocab_size_src, embed_size)\n",
        "        self.embedding_target = nn.Embedding(vocab_size_tgt, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size, max_len)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=embed_size,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=hidden_dim,\n",
        "            batch_first=False,\n",
        "            )\n",
        "        self.linear = nn.Linear(embed_size, vocab_size_tgt)\n",
        "\n",
        "\n",
        "    def forward(self, src, tgt, src_padding_mask=None, tgt_padding_mask=None, tgt_mask=None):\n",
        "\n",
        "        # 1. Get embeddings for source and target.\n",
        "        # 2. apply positional encoding to embedded source and target\n",
        "        # 3. Create a causal mask for the target to prevent seeing future tokens\n",
        "        # 4. Forward pass to Transformer block with masking\n",
        "        # 5. Project to vocabulary size\n",
        "\n",
        "        src = src.transpose(0, 1)\n",
        "        tgt = tgt.transpose(0, 1)\n",
        "        if tgt_mask != None:\n",
        "            tgt_mask = tgt_mask.transpose(0,1)\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        source_embedded = self.embedding_source(src)\n",
        "        target_embedded = self.embedding_target(tgt)\n",
        "        source_embedded = self.positional_encoding(source_embedded)\n",
        "        target_embedded = self.positional_encoding(target_embedded)\n",
        "\n",
        "        output = self.transformer(\n",
        "            src = source_embedded,\n",
        "            tgt = target_embedded,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=src_padding_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "            )\n",
        "\n",
        "\n",
        "        output = self.linear(output)\n",
        "        output = output.transpose(0, 1)\n",
        "        return output\n",
        "\n",
        "    def get_tgt_mask(self, tgt):\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device)\n",
        "        return tgt_mask\n",
        "\n",
        "    def create_pad_mask(self, matrix):\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        pad_token = 0\n",
        "        return (matrix == pad_token)\n",
        "\n",
        "def get_num_trainable_parameters(model):\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'The model has {num_params} trainable parameters.')\n",
        "    return num_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "66a7ffba-b4f2-4235-a602-bb6e6394d3ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "66a7ffba-b4f2-4235-a602-bb6e6394d3ab",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c3ae137376d5258f43b18291c31e94ed",
          "grade": true,
          "grade_id": "cell-feac3c86c1e08168",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "25cfc261-85a1-4310-b4c8-196316d472ed",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 10641353 trainable parameters.\n",
            "\u001b[92mGood job! All visible tests passed! You can proceed further.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Visible tests here\n",
        "all_tests_successful = True\n",
        "\n",
        "embedding_size = 512\n",
        "vsize_src = len(fr_word2idx) # 336\n",
        "vsize_tgt = len(en_word2idx) # 201\n",
        "hdim = 128\n",
        "model = MySimpleTransformer(vsize_src, vsize_tgt, embedding_size, 2, hdim, 3, 3, max_len=512)\n",
        "model = model.to(device)\n",
        "\n",
        "# Data\n",
        "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "src_batch, tgt_batch = next(iter(dataloader))\n",
        "\n",
        "tgt_mask = model.get_tgt_mask(tgt_batch)\n",
        "src_padding_mask = model.create_pad_mask(src_batch)\n",
        "tgt_padding_mask = model.create_pad_mask(tgt_batch)\n",
        "output = model(src_batch, tgt_batch, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask )\n",
        "\n",
        "# Check if the output shape is correct: [batch_size, seq_len, vocab_size_tgt]\n",
        "if output.size() != (1, 10, vsize_tgt):\n",
        "    all_tests_successful = False\n",
        "    raise AssertionError(f\"Expected output shape (2, 10, {vocab_size_tgt}), but got {output.size()}\")\n",
        "\n",
        "num_params = get_num_trainable_parameters(model)\n",
        "expected_num_parameters = 10641353\n",
        "if num_params != expected_num_parameters:\n",
        "    all_tests_successful = False\n",
        "    raise AssertionError(f\"Expected number of trainable parameters {expected_num_parameters}, but got {num_params}.\")\n",
        "\n",
        "\n",
        "if all_tests_successful:\n",
        "    success_str = \"Good job! All visible tests passed! You can proceed further.\"\n",
        "    print(f\"\\033[92m{success_str}\\033[0m\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fa97de74-2b5a-4521-9474-04f9b7112e0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "editable": false,
        "id": "fa97de74-2b5a-4521-9474-04f9b7112e0b",
        "outputId": "b6504f9f-26c0-49f5-e014-b80b7539c1a5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "[[  1  65   5 103  15 114   2   0   0   0]]\n",
            "[[False False False False False False False  True  True  True]]\n",
            "torch.Size([10, 10])\n",
            "[[  0. -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
            " [  0.   0. -inf -inf -inf -inf -inf -inf -inf -inf]\n",
            " [  0.   0.   0. -inf -inf -inf -inf -inf -inf -inf]\n",
            " [  0.   0.   0.   0. -inf -inf -inf -inf -inf -inf]\n",
            " [  0.   0.   0.   0.   0. -inf -inf -inf -inf -inf]\n",
            " [  0.   0.   0.   0.   0.   0. -inf -inf -inf -inf]\n",
            " [  0.   0.   0.   0.   0.   0.   0. -inf -inf -inf]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0. -inf -inf]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0. -inf]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(src_batch.size())\n",
        "print(tgt_batch.size())\n",
        "\n",
        "print(src_padding_mask.size())\n",
        "print(src_batch.cpu().detach().numpy())\n",
        "print(src_padding_mask.cpu().detach().numpy())\n",
        "\n",
        "print(tgt_mask.size())\n",
        "print(tgt_mask.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce03f944-f320-4ab2-ba28-cbeb8cb7927a",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ce03f944-f320-4ab2-ba28-cbeb8cb7927a",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0ffa9c18d5dc8110338e939c9d337b22",
          "grade": false,
          "grade_id": "cell-c94bd78980ab8c0a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "### Task 2.2: Adding Encoder and Decoder blocks\n",
        "\n",
        "The MySimpleTransformer class we implemented uses the Transformer module of PyTorch, which consists of two main parts: the encoder and the decoder. Each part of the model contains several layers of self-attention and feedforward neural networks, with the encoder and decoder connected by a cross-attention mechanism.\n",
        "\n",
        "**Self-Attention:** In the context of machine translation, self-attention allows each word in a sequence (either in the source or target language) to attend to every other word in the same sequence, regardless of their position. This mechanism enables the model to capture long-range dependencies and relationships within the sentence.\n",
        "\n",
        "**Cross-Attention:** This occurs in the decoder block, where the model attends to the encoder's output. In machine translation, cross-attention allows the decoder to focus on relevant parts of the input sequence (source language) when generating the output sequence (target language). It essentially \"crosses\" between the encoder and decoder, enabling the model to translate based on the context of both source and target sentences.\n",
        "\n",
        "Next, we will modify our Transformer block by manually separating the encoder and decoder components. This separation is necessary because, during inference (translation), the source sentence must pass through the encoder, and the generated target sentence must pass through the decoder one token at a time. This step is crucial since the translation process is autoregressive, meaning each word is predicted based on the previously generated words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a05c4ec1-3f32-4d12-b0e2-a2bd1643b0de",
      "metadata": {
        "deletable": false,
        "editable": true,
        "id": "a05c4ec1-3f32-4d12-b0e2-a2bd1643b0de",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "31b428830c77336df8f215865a3b76a1",
          "grade": false,
          "grade_id": "cell-8acf47d49c2ce752",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class MyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size_src, vocab_size_tgt, embed_size, num_heads, hidden_dim, num_encoder_layers, num_decoder_layers, max_len=512):\n",
        "        super(MyTransformer, self).__init__()\n",
        "        # Initialize layers similar to MySimpleTransformer\n",
        "        # Two Embedding layers for source and target text\n",
        "        # Positional encoding\n",
        "        # Transformer block\n",
        "        # Final linear layer to project transformer output to vocab size\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        self.embedding_source = nn.Embedding(vocab_size_src, embed_size)\n",
        "        self.embedding_target = nn.Embedding(vocab_size_tgt, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size, max_len)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=embed_size,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=hidden_dim,\n",
        "            batch_first=False,\n",
        "            )\n",
        "        self.linear = nn.Linear(embed_size, vocab_size_tgt)\n",
        "\n",
        "    def encode(self, src, src_padding_mask):\n",
        "        # Transpose inputs to (seq_len, batch_size, embedding_dim)\n",
        "        src = src.transpose(0, 1)\n",
        "\n",
        "        # 1. Get embeddings for source\n",
        "        # 2. apply positional encoding to embedded source\n",
        "        # 3. Forward pass to Transformer encoder block with src_key_padding_mask\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        source_embeded = self.embedding_source(src)\n",
        "        source_embeded = self.positional_encoding(source_embeded)\n",
        "\n",
        "        encoded = self.transformer.encoder(\n",
        "            source_embeded,\n",
        "            src_key_padding_mask=src_padding_mask\n",
        "            )\n",
        "\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, tgt, memory, tgt_mask, tgt_padding_mask):\n",
        "        # Transpose inputs to (seq_len, batch_size, embedding_dim)\n",
        "        tgt = tgt.transpose(0, 1)\n",
        "        if tgt_mask != None:\n",
        "            tgt_mask = tgt_mask.transpose(0,1)\n",
        "        # 1. Get embeddings for target\n",
        "        # 2. apply positional encoding to embedded target\n",
        "        # 3. Forward pass target and memory (output of encode) to Transformer decoder block with tgt_mask\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        target_embeded = self.embedding_target(tgt)\n",
        "        target_embeded = self.positional_encoding(target_embeded)\n",
        "\n",
        "        decoded = self.transformer.decoder(\n",
        "            target_embeded,\n",
        "            memory,\n",
        "            tgt_mask = tgt_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=src_padding_mask\n",
        "            )\n",
        "\n",
        "        return decoded\n",
        "\n",
        "    def forward(self, src, tgt, src_padding_mask=None, tgt_padding_mask=None, tgt_mask=None):\n",
        "        # 1. pass source through encode block (name it as memory)\n",
        "        # 2. pass target and memory through decode block\n",
        "        # 3. Project to vocabulary size\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        memory = self.encode(src, src_padding_mask)\n",
        "        output_decoder = self.decode(tgt, memory, tgt_mask, tgt_padding_mask)\n",
        "        output = self.linear(output_decoder)\n",
        "\n",
        "        output = output.transpose(0, 1)\n",
        "        return  output_decoder, output\n",
        "\n",
        "    def get_tgt_mask(self, tgt):\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_seq_len).to(tgt.device)\n",
        "        return tgt_mask\n",
        "\n",
        "    def create_pad_mask(self, matrix):\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        pad_token = 0\n",
        "        return (matrix == pad_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7d421762-6a59-4a20-8c05-594ea71eafac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "7d421762-6a59-4a20-8c05-594ea71eafac",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "04f7388c5f52aecc1f8f95d8e53ea635",
          "grade": true,
          "grade_id": "cell-71426ea9698049d6",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "ac7216b3-a208-42ce-de70-9f25f2b4653c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 10641353 trainable parameters.\n",
            "\u001b[92mGood job! All visible tests passed! You can proceed further.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Visible tests here\n",
        "all_tests_successful = True\n",
        "\n",
        "embedding_size = 512\n",
        "vsize_src = len(fr_word2idx) # 336\n",
        "vsize_tgt = len(en_word2idx) # 201\n",
        "hdim = 128\n",
        "model = MyTransformer(vsize_src, vsize_tgt, embedding_size, 2, hdim, 3, 3, max_len=512)\n",
        "model = model.to(device)\n",
        "\n",
        "# Data\n",
        "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=10)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "src_batch, tgt_batch = next(iter(dataloader))\n",
        "\n",
        "tgt_mask = model.get_tgt_mask(tgt_batch)\n",
        "src_padding_mask = model.create_pad_mask(src_batch)\n",
        "tgt_padding_mask = model.create_pad_mask(tgt_batch)\n",
        "_, output = model(src_batch, tgt_batch, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask = tgt_mask )\n",
        "\n",
        "# Check if the output shape is correct: [batch_size, seq_len, vocab_size_tgt]\n",
        "if output.size() != (1, 10, vsize_tgt):\n",
        "    all_tests_successful = False\n",
        "    raise AssertionError(f\"Expected output shape (2, 10, {vocab_size_tgt}), but got {output.size()}\")\n",
        "\n",
        "num_params = get_num_trainable_parameters(model)\n",
        "expected_num_parameters = 10641353\n",
        "if num_params != expected_num_parameters:\n",
        "    all_tests_successful = False\n",
        "    raise AssertionError(f\"Expected number of trainable parameters {expected_num_parameters}, but got {num_params}.\")\n",
        "\n",
        "if all_tests_successful:\n",
        "    success_str = \"Good job! All visible tests passed! You can proceed further.\"\n",
        "    print(f\"\\033[92m{success_str}\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f478708b-68d0-4690-8bed-3629ea2e4b2d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f478708b-68d0-4690-8bed-3629ea2e4b2d",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bfdc594c1314d46e6f092e7117d03e55",
          "grade": false,
          "grade_id": "cell-2f77cd749e40453a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "## Task 3: Training and Evaluation\n",
        "\n",
        "So far, we have defined our dataset class and the Transformer model. The next step is to train and validate the model. We will split the data into training and validation sets, with an 80% training and 20% validation ratio, and run the training and validation loops accordingly.\n",
        "\n",
        "For the model, we will define a simple Transformer with a hidden dimension of 512, 4 encoder layers, 4 decoder layers, and 6 attention heads. We will use cross-entropy loss, which is well-suited for Transformer-based machine translation because it measures the difference between the predicted probability distribution and the true distribution for each token in the sequence. This loss function helps the model optimize the prediction accuracy for each word in the target sequence. Additionally, we will use the Adam optimizer to efficiently minimize the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5b833b15-348a-447c-9c6e-185ec36736d7",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5b833b15-348a-447c-9c6e-185ec36736d7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3e3d07d2cc6c623d73b169e5acc2771b",
          "grade": false,
          "grade_id": "cell-50417a72b48171e1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "\n",
        "bs = 256\n",
        "dataset = TranslationDataset(tokenized_fr, tokenized_en, fr_word2idx, en_word2idx,  seq_len=7)\n",
        "number_of_sentences = len(tokenized_fr)\n",
        "train_size = int((0.8)*number_of_sentences)\n",
        "test_size = int(number_of_sentences - train_size)\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "efd32c9e-9868-4f8a-819d-6816332a9ea7",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "efd32c9e-9868-4f8a-819d-6816332a9ea7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ada45fd309f153dcb7c3f001c5acddc8",
          "grade": false,
          "grade_id": "cell-47986e3c9b4441ee",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "embedding_size = 240 # embed_dim must be divisible by num_heads\n",
        "vsize_src = len(fr_word2idx) # 336\n",
        "vsize_tgt = len(en_word2idx) # 201\n",
        "hdim = 512\n",
        "model = MyTransformer(vsize_src, vsize_tgt, embedding_size, 6, hdim, 4, 4, max_len=256)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "17e63f9b-07b4-4d01-a62d-25b9deafaf5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "deletable": false,
        "editable": true,
        "id": "17e63f9b-07b4-4d01-a62d-25b9deafaf5a",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "65de115ec5ce2d0baed8313bf2220f2b",
          "grade": false,
          "grade_id": "cell-3e78e5aa606c25be",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "5cb7d435-f36b-483d-a46d-a36f30646578",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 1.0227\n",
            "Epoch 1/10, Validation Loss: 0.1463\n",
            "Epoch 2/10, Train Loss: 0.1331\n",
            "Epoch 2/10, Validation Loss: 0.0896\n",
            "Epoch 3/10, Train Loss: 0.0924\n",
            "Epoch 3/10, Validation Loss: 0.078\n",
            "Epoch 4/10, Train Loss: 0.0818\n",
            "Epoch 4/10, Validation Loss: 0.0744\n",
            "Epoch 5/10, Train Loss: 0.077\n",
            "Epoch 5/10, Validation Loss: 0.0728\n",
            "Epoch 6/10, Train Loss: 0.0744\n",
            "Epoch 6/10, Validation Loss: 0.0732\n",
            "Epoch 7/10, Train Loss: 0.073\n",
            "Epoch 7/10, Validation Loss: 0.0711\n",
            "Epoch 8/10, Train Loss: 0.0716\n",
            "Epoch 8/10, Validation Loss: 0.0698\n",
            "Epoch 9/10, Train Loss: 0.071\n",
            "Epoch 9/10, Validation Loss: 0.0694\n",
            "Epoch 10/10, Train Loss: 0.0701\n",
            "Epoch 10/10, Validation Loss: 0.0701\n",
            "Training completed.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "num_epochs = 10\n",
        "\n",
        "if not skip_training:\n",
        "    epoch_train_losses = []\n",
        "    epoch_validation_losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model = model.to(device)\n",
        "        model.train()  # Set model to training mode\n",
        "        total_loss = 0\n",
        "        num_samples = 0\n",
        "        for src_batch, tgt_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            # set input source as src_batch\n",
        "            # set input target as start of target sentence untill -1 (i.e. discard the last token) (past) [name it as tgt_input]\n",
        "            # set expexted target as target sentence from 1 to the end (i.e. discard the first token) (future) [name it as tgt_expected]\n",
        "            # use input source and input target (tgt_input) as input to the model\n",
        "            # expexted target will be used in loss to compare it with the model output.\n",
        "            # Remember to use padding and target causal masks on the model call:\n",
        "            # get padding mask of source,\n",
        "            # get padding mask of input target, convert it to float (.float()),\n",
        "            # get tgt_mask of input target,\n",
        "            # pass inout source, input target, source padding mask, and tgt_mask to the model to get the predictions (output).\n",
        "\n",
        "            # YOUR CODE HERE\n",
        "            src_input = src_batch\n",
        "            tgt_input = tgt_batch[:, :-1]\n",
        "            tgt_expected = tgt_batch[:, 1:]\n",
        "\n",
        "            src_padding_mask = model.create_pad_mask(src_input).to(device).float()\n",
        "            tgt_padding_mask = model.create_pad_mask(tgt_input).to(device).float()\n",
        "            tgt_mask = model.get_tgt_mask(tgt_input).to(device).float()\n",
        "\n",
        "            output_decoder, output = model(\n",
        "                src_input,\n",
        "                tgt_input,\n",
        "                src_padding_mask,\n",
        "                tgt_padding_mask,\n",
        "                tgt_mask,\n",
        "                )\n",
        "            output = output.to(device)\n",
        "            output = output.contiguous().view(-1, vsize_tgt)\n",
        "            tgt_expected = tgt_expected.contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output, tgt_expected)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_samples += src_batch.shape[0]\n",
        "\n",
        "        epoch_train_loss = total_loss / len(train_loader)\n",
        "        epoch_train_loss = round(epoch_train_loss, 4)\n",
        "        epoch_train_losses.append(epoch_train_loss)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_train_loss}\")\n",
        "\n",
        "        ################################################################\n",
        "\n",
        "        model.eval()\n",
        "        validation_loss = 0\n",
        "        num_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for src_batch, tgt_batch in val_loader:\n",
        "                # set input source as src_batch\n",
        "                # set input target as start of target sentence untill -1 (i.e. discard the last token) (past) [name it as tgt_input]\n",
        "                # set expexted target as target sentence from 1 to the end (i.e. discard the first token) (future) [name it as tgt_expected]\n",
        "                # use input source and input target (tgt_input) as input to the model\n",
        "                # expexted target will be used in loss to compare it with the model output.\n",
        "                # Remember to use padding and target causal masks on the model call:\n",
        "                # get padding mask of source,\n",
        "                # get padding mask of input target, convert it to float (.float()),\n",
        "                # get tgt_mask of input target,\n",
        "                # pass inout source, input target, source padding mask, and tgt_mask to the model to get the predictions (output).\n",
        "\n",
        "                # YOUR CODE HERE\n",
        "                src_input = src_batch\n",
        "                tgt_input = tgt_batch[:, :-1]\n",
        "                tgt_expected = tgt_batch[:, 1:]\n",
        "\n",
        "                src_padding_mask = model.create_pad_mask(src_input).to(device).float()\n",
        "                tgt_padding_mask = model.create_pad_mask(tgt_input).to(device).float()\n",
        "                tgt_mask = model.get_tgt_mask(tgt_input).to(device).float()\n",
        "\n",
        "                output_decoder, output = model(\n",
        "                    src_input,\n",
        "                    tgt_input,\n",
        "                    src_padding_mask,\n",
        "                    tgt_padding_mask,\n",
        "                    tgt_mask\n",
        "                )\n",
        "\n",
        "                output = output.to(device)\n",
        "                output = output.contiguous().view(-1, vsize_tgt)\n",
        "                tgt_expected = tgt_expected.contiguous().view(-1)\n",
        "                loss = criterion(output, tgt_expected)\n",
        "                validation_loss += loss.item()\n",
        "                num_samples += src_batch.shape[0]\n",
        "\n",
        "            epoch_validation_loss = validation_loss / len(val_loader)\n",
        "            epoch_validation_loss = round(epoch_validation_loss, 4)\n",
        "            epoch_validation_losses.append(epoch_validation_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {epoch_validation_loss}\")\n",
        "        torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "    print(\"Training completed.\")\n",
        "    torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    epochs = range(1, num_epochs + 1)\n",
        "    plt.plot(epochs, epoch_train_losses, label='Train Loss', color='blue', marker='o')\n",
        "    plt.plot(epochs, epoch_validation_losses, label='Validation Loss', color='red', marker='x')\n",
        "    plt.title('Train vs Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "463af138-b291-49b6-a74c-521328e684a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "463af138-b291-49b6-a74c-521328e684a6",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "10bd60e70fa72570e2d7362277a91833",
          "grade": false,
          "grade_id": "cell-2558e4570d6e8afe",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "25a591a7-2d00-4d75-88e0-28648dae63f5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mGood job! The final train loss and validation loss are in the expected range!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Visible tests here\n",
        "all_tests_successful = True\n",
        "# Visible tests for checking the performance of the trained model\n",
        "# Test if the train and validation losses are within the correct range\n",
        "if not skip_training:\n",
        "    if not (epoch_train_loss <= 0.1):\n",
        "        all_tests_successful = False\n",
        "        raise AssertionError(f\"Training loss {epoch_train_loss} must be smaller than 0.1\")\n",
        "\n",
        "    if not (epoch_validation_loss <= 0.1):\n",
        "        all_tests_successful = False\n",
        "        raise AssertionError(f\"Validation loss {epoch_validation_loss} must be smaller than 0.1\")\n",
        "\n",
        "    if all_tests_successful:\n",
        "        success_str = \"Good job! The final train loss and validation loss are in the expected range!\"\n",
        "        print(f\"\\033[92m{success_str}\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d97d50-f344-4bd0-9933-31e0967db8ff",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e4d97d50-f344-4bd0-9933-31e0967db8ff",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3cd6f4b79c9eb03096892f79e8f40433",
          "grade": false,
          "grade_id": "cell-c54877793b096ca1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "tags": []
      },
      "source": [
        "## Task 4: Autoregressive Translation\n",
        "\n",
        "Finally, we are going to use the trained model to perform an actual translation task, translating French sentences into English. Exciting!\n",
        "\n",
        "The inference works in an autoregressive manner. This means that, during the translation process, the model generates each token in the target sequence one at a time, using the previously generated token as input for predicting the next one. At each step, the model uses the encoded source sentence along with the target sequence generated so far to predict the next word. This approach allows the model to produce the translation step by step, instead of generating the entire sequence at once.\n",
        "\n",
        "The steps for translation are as follows:\n",
        "\n",
        "**Source Sentence Encoding:** First, we obtain the source sequence embedding and pass it through the encoder to obtain its encoded representation.\n",
        "\n",
        "**Initializing Target Sentence with <SOS> Token:** We initialize the target sentence with the special <SOS> (Start Of Sentence) token, which indicates the beginning of the translation.\n",
        "\n",
        "**Autoregressive Loop to Translate Target Tokens One at a Time:** We enter a loop where the model predicts the next token in the sequence based on the previously generated token and the encoded source sentence. This loop continues until the model predicts the <EOS> (End Of Sentence) token or the maximum sequence length is reached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7b511cb3-8a3d-4d83-b403-ffb9f4b65f5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": true,
        "id": "7b511cb3-8a3d-4d83-b403-ffb9f4b65f5e",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a7d107bba2e8b29eabdd5bde898afb0b",
          "grade": false,
          "grade_id": "cell-4dae7ac8dd1330c2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "b48986e3-495d-4831-9f5c-51258dd192c0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original_sentence: new jersey est parfois calme pendant l' automne.\n",
            "translated_sentence: quiet during autumn <EOS>\n",
            "----------\n",
            "original_sentence: california est généralement calme en mars.\n",
            "translated_sentence: during march <EOS>\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "seq_len=10\n",
        "start_token=1\n",
        "end_token=2\n",
        "model.eval()\n",
        "\n",
        "# Convert src_sentence to tokenized integers in the vocabulary dictionary\n",
        "example_source_sentences = [\"new jersey est parfois calme pendant l' automne.\", \"california est généralement calme en mars.\"]\n",
        "example_tokenized = tokenize(example_source_sentences)\n",
        "src_sentences = []\n",
        "for ex in example_tokenized:\n",
        "    ex_inds = []\n",
        "    for t in ex:\n",
        "        t_ind = fr_word2idx [t]\n",
        "        ex_inds.append(t_ind)\n",
        "    src_sentences.append(ex_inds)\n",
        "\n",
        "translated_sequences = []\n",
        "for counter, src_sentence in enumerate(src_sentences):\n",
        "    # Convert source tokens to Tensor\n",
        "    src_tensor = torch.tensor(src_sentence, dtype=torch.long).unsqueeze(0).to(device)  # Shape: (1, src_seq_length)\n",
        "\n",
        "    # 1. create src_padding_mask\n",
        "    # 2. get \"memory\" by passing source with create src_padding_mask through encode block (model.encode)\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    src_padding_mask = model.create_pad_mask(src_tensor).to(device)\n",
        "    memory = model.encode(src_tensor, src_padding_mask)\n",
        "\n",
        "    # initialize the predicted tgt_tokens (translation) with start token\n",
        "    tgt_tokens = torch.ones(1, 1).fill_(start_token).type(torch.long).to(device) #(1,1)\n",
        "\n",
        "    for i in range(seq_len-1):\n",
        "        # 1. Mask out the unpredicted tokens in the target (i.e., get tgt_mask)\n",
        "        # 2. get output by passing target (the generated part up to current `i`) and memory to decode block (model.decode)\n",
        "        # 3. remember to pass also tgt_mask\n",
        "        # 4. get a probability vector by passing output through linear layer (projection to vocabulary size)\n",
        "        # 5. use \"torch.max\" to get the index of the predicted word\n",
        "        # 6. Convert it to a tensor on device (name it as \"next_tgt_item\")\n",
        "        # 7. add \"next_tgt_item\" to tgt_tokens (use torch.cat)\n",
        "        # 8. Stop (break) if \"end_token\" is generated\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        tgt_mask = model.get_tgt_mask(tgt_tokens).to(device)\n",
        "        output_decoder = model.decode(tgt_tokens, memory, tgt_mask, None)\n",
        "        output = model.linear(output_decoder)\n",
        "        prob = output[-1, :, :]\n",
        "        _, next_tgt_item = torch.max(prob, dim = 1, keepdim = True)\n",
        "        tgt_tokens = torch.cat([tgt_tokens, next_tgt_item], dim=1)\n",
        "        if next_tgt_item.item() == end_token:\n",
        "            break\n",
        "\n",
        "\n",
        "    translated_tokens = tgt_tokens.squeeze().tolist()\n",
        "    translated_sentence = ' '.join ([en_idx2word[i] for i in translated_tokens[1:]])\n",
        "    translated_sequences.append(translated_tokens)\n",
        "    print(\"original_sentence:\", example_source_sentences[counter])\n",
        "    print(\"translated_sentence:\", translated_sentence)\n",
        "    print(10*'-')\n",
        "\n",
        "np.save('translation.npy', np.array(translated_sequences, dtype=object))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "toc": {
      "base_numbering": 0
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
